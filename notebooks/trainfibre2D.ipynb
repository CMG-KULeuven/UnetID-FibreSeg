{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a92bda",
   "metadata": {},
   "source": [
    "# Train the Unet_ID to segment each fibre\n",
    "- Author: Rui Guo (KU Leuven), rui.guo1@kuleuven.be\n",
    "- Date: Jan 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef4aaef",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fibresegt as fs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aa1572",
   "metadata": {},
   "source": [
    "## Specify the output folder you want to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47d11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './output/demo/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cdc41c",
   "metadata": {},
   "source": [
    "## Load the images\n",
    "Get the images from the data folder.  \n",
    "Notice: only one image is required during the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c421d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These two variable needs to be changed according to your purpose\n",
    "dataset_folder = './data/demo/training_data/grayscale_slice/'\n",
    "dataset_name = 'slice_00000_H300-250_550_W150-250_400.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb47f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = fs.join(dataset_folder, dataset_name)\n",
    "origData = np.array(fs.imread(dataset_file))\n",
    "fs.data_info(origData)\n",
    "plt.figure()\n",
    "plt.imshow(origData, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c8aeea",
   "metadata": {},
   "source": [
    "## Create or load masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f41ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_folder = './data/demo/training_data/mask_slice/'\n",
    "label_name = 'Masks_'+dataset_name[:-4]+'.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5de9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file = fs.join(label_folder + label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1223fc3c-fdee-47d3-86a9-21225d32aa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = dict(dataset_file=dataset_file, \n",
    "                 label_file=label_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c39cf2",
   "metadata": {},
   "source": [
    "### (A) Manual annotation\n",
    "If you don't have the label for your dataset, you need to annotate it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e9c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fs.annotate(origData, label_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7370bff9",
   "metadata": {},
   "source": [
    "### (B) Load the masks\n",
    "If you have the label for your dataset already, you don't need to annotate again, just import it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35128fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelInnerFibre = np.array(fs.imread(label_file))\n",
    "if labelInnerFibre.ndim > 2:\n",
    "    labelInnerFibre = labelInnerFibre[:,:,0]\n",
    "fs.data_info(labelInnerFibre)\n",
    "plt.figure()\n",
    "plt.imshow(labelInnerFibre, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35ebb9a",
   "metadata": {},
   "source": [
    "## Sample  \n",
    "- **1. Choose the image size**  \n",
    "This is used to set the image size for samples\n",
    "- **2. Choose the stride_step for training and validation**   \n",
    "This is used to set how to sample the images. If the step size is equal to the image size, then there will not be overlapping areas.\n",
    "- **3. Choose the itera_size**  \n",
    "This is used to extend the fibre edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740b8740",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size          = (64, 64)\n",
    "train_stride_step   = 8\n",
    "itera_enlarge_size  = 2\n",
    "fig_path            = fs.join(label_folder, 'crop_data')\n",
    "save_fig            = False\n",
    "sample_info         = dict(image_size = image_size, \n",
    "                           train_stride_step=train_stride_step, \n",
    "                           itera_enlarge_size=itera_enlarge_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209a4b22",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "Data = fs.generate_training_samples(data=[origData, labelInnerFibre], \n",
    "                                    stride_step=train_stride_step, \n",
    "                                    data_shape=image_size, \n",
    "                                    itera_enlarge_size=itera_enlarge_size,\n",
    "                                    fig_path=fig_path,\n",
    "                                    save_fig=save_fig,\n",
    "                                    show_img=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babb9396",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e94ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data               = Data\n",
    "image_size         = (64, 64)\n",
    "val_percent        = 0.0 # The probability to split the data as training and testing\n",
    "epochs             = 200\n",
    "batch_size         = 16\n",
    "learning_rate      = 0.001\n",
    "net_var            = 'UnetID'\n",
    "data_aug           = {'brightness':0.3, 'contrast':0.3,\n",
    "                      'GaussianBlur_kernel':5, 'GaussianBlur_sigma': (0.7, 1.3)}\n",
    "# data_aug           = None\n",
    "preprocess_info    = dict(data_info=data_info,\n",
    "                          sample_info=sample_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a58a942",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.apis.train_net(Data=Data, image_size=image_size, output_dir=output_dir, \n",
    "                  val_percent=val_percent, epochs=epochs, batch_size=batch_size,\n",
    "                  learning_rate=learning_rate, net_var=net_var, \n",
    "                  data_aug=data_aug,\n",
    "                  preprocess_info=preprocess_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cabed04-adc0-4559-90a3-54b00e9a8059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "6101ffe372936956a9fe06ac5712653a4b4e7ea1cd4b3a5cf2e29e99cbc16662"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
